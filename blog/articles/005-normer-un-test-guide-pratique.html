<p>Normer un test, c’est transformer des réponses en une mesure utile et comparable dans le temps. Si vous me connaissez, vous savez que je refuse les chiffres-magie. Un score de QI doit être lisible visuellement, solide psychométriquement, accessible par design et explicite sur ses limites. Dans ce guide, je montre comment fixer une moyenne à 100 et un écart-type à 15 à partir d’un échantillon bien construit, pour des tests modernes, visuels et mobiles. Nous allons parler de population normative, d’accessibilité WCAG, de calibration CTT/IRT, de transformation des scores et d’équité. Le ton est franc, la méthode concrète, et chaque choix est relié à son impact sur l’expérience utilisateur et la validité des résultats.</p>

<h2>Cadrer la population normative et l’échantillonnage stratifié</h2>
<p>Avant toute équation, il faut une question claire: «Pour qui ce score doit-il être représentatif?» Un test normé pour des adultes francophones connectés n’est pas interchangeable avec un test pour des collégiens bilingues. <strong>Définir la population cible</strong> est l’acte fondateur. Je recommande de documenter cinq axes: âge, niveau d’études, région/zone urbaine-rurale, langue/usages numériques, et accessibilité (vision, motricité, audio).</p>

<p>Ensuite, on échantillonne de façon <strong>stratifiée</strong>, en fixant des quotas qui reflètent la structure de la population ciblée. Pour un test visuel mobile, j’ajoute des strates techniques: type d’appareil (iOS/Android), taille d’écran (petit < 5,8”, moyen, grand), contraste d’écran, et qualité de connexion. Pourquoi? Parce que les temps de réaction, la lisibilité des motifs et même la fatigue visuelle dépendent du device. Ignorer ces variables produit des normes qui favorisent implicitement un sous-groupe (typiquement, écrans grands et récents).</p>

<p>Les standards AERA/APA/NCME insistent sur la représentativité et la documentation. Les batteries Wechsler ou le WJ adoptent des échantillons d’environ 2000 à 3000 sujets, avec des partitions d’âge fines et des sur-échantillonnages pour les minorités. <strong>Pour un test de raisonnement visuel court</strong>, je vise au minimum N=1500 pour l’ensemble, et N≥200 par tranche d’âge de 5 ans (ou N≥300 si vous voulez estimer des percentiles extrêmes avec moins de bruit).</p>

<h3>Repères chiffrés pour la taille d’échantillon</h3>
<ul>
<li><strong>Objectif global</strong>: N≥2000 si vous publiez des percentiles par âge; N≥1000 pour un lancement en bêta avec mise à jour planifiée.</li>
<li><strong>Par tranche d’âge</strong> (5 ans): N≥200 acceptable; N≥400 recommandé (meilleure stabilité des 10e et 90e percentiles).</li>
<li><strong>Sous-groupes techniques</strong> (p. ex., petits écrans): N≥150 si vous voulez tester des effets de device (ANCOVA ou IRT-DIF).</li>
<li><strong>Test–retest</strong>: échantillon indépendant N≥150 avec délai de 2 à 4 semaines pour estimer la fidélité temporelle.</li>
</ul>

<p>Enfin, préparez une documentation publique: critères d’inclusion/exclusion, dates de collecte, canaux de recrutement, et description des incitations (compensation, badges, etc.). Transparence = confiance.</p>

<h2>Protocoles de collecte: expérience mobile, accessibilité et biais minimisés</h2>
<p>La manière dont on recueille les données modèle la norme que l’on obtiendra. Mes tests sont <strong>visuels, peu verbaux</strong>, avec des règles simples illustrées avant chaque bloc. On réduit le texte, on augmente la clarté graphique, et on explicite les interactions: tap, glisser, double tap, retour haptique. Les consignes sont iconographiques, avec un court texte en langage clair et une voix off optionnelle.</p>

<p><strong>Accessibilité (WCAG 2.2)</strong> intégrée dès le design:</p>
<ul>
<li>Contraste minimum 4,5:1 pour les éléments informatifs; 7:1 dans les écrans d’instructions.</li>
<li>Métriques alternatives au code couleur: motifs, formes, textures pour différencier des réponses.</li>
<li>Taille de cible tactile ≥ 44x44 px; distances suffisantes pour éviter les taps accidentels.</li>
<li>Rythme contrôlé: pas de stimuli qui clignotent au-delà de 3 Hz; limite les animations.</li>
<li>Options d’assistance: pause entre items, réglage du volume, texte de grande taille, mode daltonisme.</li>
</ul>

<p><strong>Inputs à collecter</strong> pendant la passation:</p>
<ul>
<li>Version du test et de l’algorithme (hash), langue de l’interface, thèmes de contraste.</li>
<li>Données device: OS, taille écran, densité de pixels, luminosité (si autorisée), orientation.</li>
<li>Qualité réseau, latence estimée, frame rate (si pertinent pour stimuli dynamiques).</li>
<li>Métriques par item: réponse, correct/incorrect, temps de réaction, nombre d’essais, abandon.</li>
<li>Catch trials (items sentinelles) et attention checks visuels.</li>
</ul>

<p><strong>Outputs attendus</strong>: un jeu de données brut horodaté, un log des événements (incluant focus/blur), et un fichier de métadonnées exhaustif. Sans métadonnées, les corrections d’effets de device restent du bricolage.</p>

<p>Pour limiter les biais d’apprentissage, je fais précéder chaque sous-test de 2 à 4 essais d’entraînement avec feedback visuel, puis je coupe le feedback. Les items sont présentés dans un ordre pseudo-aléatoire, contenu équilibré par bloc, avec un temps total de 8 à 15 minutes. Cette durée optimise la fidélité sans fatiguer, à la manière des mesures rapides modernes (voir le travail de van der Maas et al. sur l’IRT adaptative dans des paradigmes brefs).</p>

<h2>Nettoyage et contrôle qualité avant la calibration</h2>
<p>Le nettoyage n’est pas glamour, mais c’est là que se joue la qualité des normes. Les mobiles introduisent bruit et artefacts de timing. On a besoin de règles claires, déclarées à l’avance (<strong>prereg</strong> si possible):</p>

<ul>
<li><strong>Doublons</strong>: identifiants, empreinte device, timestamps. Garder la première passation complète.</li>
<li><strong>Temps impossibles</strong>: seuil empirique par item. Par exemple, un tap correct en moins de 250–300 ms sur un motif complexe est suspect. On définit des seuils par distribution (p. ex., < 1e percentile du temps de réaction par item) et on marque, sans exclure automatiquement.</li>
<li><strong>Catch trials</strong>: si plus de 1 erreur sur 3 items très faciles, exclusion probable.</li>
<li><strong>Patrons de réponse</strong> en ligne droite (toujours la première option), alternances mécaniques, ou temps quasi constants indépendants de la difficulté.</li>
<li><strong>Manquants</strong>: si >20% d’items manquants, il s’agit d’un abandon. On n’intègre pas aux normes.</li>
<li><strong>Conditions matérielles</strong>: frame drops sévères, latence extrême. Selon la gravité, on exclut ou on annote pour analyse de sensibilité.</li>
</ul>

<p>Ensuite, on calcule des indicateurs rapides:</p>
<ul>
<li><strong>Distribution des scores bruts</strong> par strata d’âge: repérer plafonds/effets plancher.</li>
<li><strong>Homogénéité</strong>: corrélations item-total, alpha de Cronbach et oméga (McDonald). Objectif: α ≥ 0,85 pour un court test de raisonnement; si <0,8, revoir le contenu.</li>
<li><strong>Fidélité test–retest</strong>: corrélation à 2–4 semaines; viser r ≥ 0,85 pour un score composite.</li>
</ul>

<h3>Erreurs fréquentes à éviter</h3>
<ul>
<li><strong>Élagage ex post à la tête du client</strong>: retirer après coup des sujets qui «déplaisent» au modèle gonfle artificiellement la fidélité.</li>
<li><strong>Sous-estimer l’effet device</strong>: des écarts de 2–4 points de QI normés sont possibles entre petits et grands écrans si les stimuli ne sont pas responsives.</li>
<li><strong>Confondre vitesse et intelligence</strong>: si la vitesse domine, on mesure la motricité et la familiarité tactile. Limiter l’influence du temps via des fenêtres larges et des scores axés sur l’exactitude.</li>
<li><strong>Négliger la langue</strong> même dans un test visuel: micro-texte des consignes et symboles culturels peuvent introduire des biais.</li>
</ul>

<h2>Calibrer les items: CTT et IRT, choix pragmatiques</h2>
<p>La <strong>CTT</strong> (théorie classique des tests) fournit des indices simples: difficulté p, discrimination rit, et contribution à l’alpha. La <strong>IRT</strong> (Item Response Theory) offre une calibration qui sépare l’aptitude du répondant et les paramètres des items, et c’est précieux pour l’adaptatif, l’équating et l’estimation précise aux extrêmes.</p>

<p>Mes règles pragmatiques:</p>
<ul>
<li><strong>Raisonnement visuel binaire</strong> (correct/incorrect): modèle 2PL par défaut; j’évite le 3PL sauf si guessing évident (quatre options proches). Le 3PL est capricieux sur mobiles et demande de gros N.</li>
<li><strong>Crédit partiel</strong> (p. ex., matrices avec étapes): modèle GPCM (Muraki). Il améliore la fidélité sans rallonger le test.</li>
<li><strong>Estimation</strong>: MML avec priors faiblesment informatifs; vérification par bootstrap paramétrique.</li>
<li><strong>DIF</strong> (fonctionnement différentiel des items) sur sexe, tranche d’âge, langue, device. Un item avec DIF modéré sur device doit être redessiné ou exclu.</li>
</ul>

<p>On examine les <strong>courbes d’information</strong>: l’objectif est d’avoir une information élevée autour de θ ≈ −1 à +2 (zone la plus fréquente et cliniquement utile). Si l’information s’effondre en θ>2, ajoutez des items plus difficiles pour éviter l’effet plafond chez les hauts niveaux.</p>

<h3>Exemple visuel: item de matrices mobiles</h3>
<p>Stimulus: grille 3x3, règle de progression par rotation et alternance de densité de motifs. Quatre réponses candidates, formes géométriques noires et blanches avec textures pour daltonisme.</p>

<p>Scoring:</p>
<ul>
<li><strong>Binaire</strong>: 1 si bonne réponse, 0 sinon. Temps ignoré sauf si &lt;300 ms (flag).</li>
<li><strong>Crédit partiel</strong>: 1 si bonne réponse, 0,5 si réponse qui respecte une des deux règles sous-jacentes mais pas l’autre (détecté par pattern d’erreur).</li>
</ul>

<p>Calibration typique (2PL): a=1,35, b=0,15. L’item discrimine correctement autour de θ=0, sensible à la légère difficulté. Si DIF sur petits écrans (b augmente de 0,4), on agrandit la zone cliquable, on simplifie les textures, et on reteste.</p>

<h2>Transformer les bruts vers μ=100, σ=15: la normalisation pas à pas</h2>
<p>Le but est simple: sur la population cible, la distribution des scores standardisés a une <strong>moyenne 100 et un écart-type 15</strong>. Pour y arriver, la route dépend de votre modèle.</p>

<p><strong>Cas IRT (recommandé)</strong>:</p>
<ol>
<li>Estimez θ pour chaque sujet par EAP ou MLE avec les paramètres d’items fixés.</li>
<li>θ suit en général une loi proche de N(0,1) si vous avez utilisé une normalisation lors de la calibration (moyenne 0, variance 1).</li>
<li>Appliquez la transformation linéaire: IQ = 100 + 15 × θ.</li>
<li>Vérifiez par tranche d’âge que la moyenne est ~100 et l’ET ~15. Si vous utilisez la même calibration pour tous, il faut <strong>équiper</strong> des normes d’âge via une correction de biais (voir ci-dessous).</li>
</ol>

<p><strong>Cas CTT (scores bruts)</strong>:</p>
<ol>
<li>Calculez, par groupe d’étalonnage (p. ex., 20–24 ans), la moyenne μ_g et l’écart-type σ_g des scores bruts.</li>
<li>Obtenez un z-score: z = (score_brut − μ_g) / σ_g.</li>
<li>Transformez: IQ = 100 + 15 × z.</li>
<li>Si la distribution est tronquée ou fortement non normale, préférez une <strong>normation continue</strong> par régression (LMS ou quantile regression) pour mappeur score→percentile→IQ.</li>
</ol>

<p>Deux points de rigueur:</p>
<ul>
<li><strong>Âge et normes</strong>: à moins d’un test strictement invariant, la performance moyenne varie avec l’âge. On pratique des normes par tranches (p. ex., 16–19, 20–24, 25–34, 35–44, …) ou des <strong>normes continues</strong> en modélisant le score en fonction de l’âge (splines). L’approche continue évite les ruptures artificielles aux frontières d’âge.</li>
<li><strong>Monotonicité et lissage</strong>: si les percentiles «ondulent» entre tranches adjacentes, liez les courbes de transformation et lissez avec des splines monotones. Ne jamais rendre un score brut plus élevé conduisant à un IQ plus bas.</li>
</ul>

<h3>Exemple pas à pas</h3>
<p>Supposons un sous-test de matrices, 36 items. Tranche d’âge: 20–24 ans, N=320. Moyenne des bruts μ=26,4; écart-type σ=5,8.</p>

<p>Une personne obtient 31/36. Calcul CTT:</p>
<ul>
<li>z = (31 − 26,4) / 5,8 = 0,793.</li>
<li>IQ = 100 + 15 × 0,793 = 111,9, arrondi à 112.</li>
</ul>

<p>Si vous avez une calibration IRT et une estimation θ=0,65 pour la même personne:</p>
<ul>
<li>IQ_IRT = 100 + 15 × 0,65 = 109,8, arrondi à 110.</li>
</ul>

<p>Les deux méthodes diffèrent légèrement. L’IRT est souvent plus juste aux extrêmes, surtout si le test est adaptatif. Reportez le <strong>SEM</strong> associé: si SEM_θ=0,22, alors SEM_IQ ≈ 15 × 0,22 = 3,3. Vous pouvez communiquer un intervalle individuel raisonnable: 110 ± 6,6 pour ~95% si normalité tenue.</p>

<p><strong>Cas des extrêmes</strong>: au-delà du 98e percentile, les estimations deviennent sensibles à la calibration et à la rareté des observations. Je limite la communication à un intervalle et un percentile («≥ 99e percentile») plutôt qu’un chiffre absolu hyper précis. L’honnêteté prime sur l’illusion de précision.</p>

<p><strong>Choix de l’échelle et bornes</strong>: l’échelle 100/15 vient de conventions historiques (Binet, puis Wechsler). Je déconseille de tronquer durement à 40–160. Si vous devez afficher une borne pour éviter les surinterprétations, indiquez «≤ 55» ou «≥ 145» et expliquez le plafond technique.</p>

<p><strong>Équating et multi-formes</strong>: si vous avez des formes A et B, utilisez des items ancres pour relier les calibrations. Méthodes: Stocking-Lord (IRT) ou équating linéaire (CTT) si nécessaire. On place ensuite la distribution globale sur la métrique 100/15, puis on vérifie par sous-groupes que la moyenne n’est pas décalée (sinon, rétrotuning des paramètres).</p>

<h2>Rapporter les résultats: percentiles, SEM, équité et mises à jour</h2>
<p>Un score sans incertitude est un storytelling dangereux. Je fournis toujours trois informations:</p>
<ul>
<li><strong>Score standardisé</strong> (m=100, ET=15) avec arrondi au point le plus proche.</li>
<li><strong>Intervalle d’erreur</strong> basé sur le SEM au niveau du score (ou du θ). Exemple: ±1,96 × SEM.</li>
<li><strong>Percentile</strong>, calculé sur les normes d’âge. Indiquez s’il s’agit d’un percentile interpolé ou exact.</li>
</ul>

<p>Pour l’UX, j’utilise une jauge visuelle simple avec un <strong>contraste élevé</strong>, des repères à 70, 85, 100, 115, 130, et un texte clair: «Votre score se situe autour de 112 (intervalle 106–118), soit environ le 79e percentile pour votre tranche d’âge.» Pas d’étoiles, pas de proclamations de génie. Je rappelle que le test mesure surtout le <strong>raisonnement visuel</strong> dans un format mobile court; il ne capture pas toutes les facettes cognitives.</p>

<p><strong>Équité et biais</strong> ne s’arrêtent pas à la calibration. Je publie un rapport synthétique:</p>
<ul>
<li>Analyse DIF résiduelle par sexe, langue, device et daltonisme déclaré.</li>
<li>Écarts moyens de score par sous-groupes, avec correction de la covariable âge/éducation.</li>
<li>Taux d’abandon et difficultés d’accessibilité rapportées.</li>
</ul>

<p>Si des écarts persistent, je propose des <strong>ajustements de design</strong> plutôt que des «corrections» de score. Exemples: agrandir les zones de réponse, ralentir la cadence d’apparition, adapter la luminosité, fournir un mode à haut contraste. L’éthique, c’est corriger le test, pas les testés.</p>

<p><strong>Mises à jour des normes</strong>: le monde bouge, les normes aussi. Le «Flynn effect» a ralenti voire inversé dans certaines régions, mais la pratique numérique progresse. Je planifie:</p>
<ul>
<li>Une <strong>surveillance continue</strong> via un flux de consentants pour l’analyse anonyme.</li>
<li>Des <strong>micro-ajustements</strong> interdits; je préfère des mises à jour datées et documentées (p. ex., v2027) pour préserver la comparabilité.</li>
<li>Un cycle de révision majeur tous les 5–7 ans, ou plus tôt si un changement notable est observé (décalage > 0,3 ET).</li>
</ul>

<p>Pour ceux qui utilisent le test en recherche, je fournis des <strong>tables de conversion</strong> par version, des scripts reproductibles (R/Python) et un changelog. Rien à cacher: c’est ainsi que l’on bâtit la confiance.</p>

<h2>Procédure opérationnelle complète: étapes, inputs/outputs, risques</h2>
<p>Voici la procédure condensée que j’applique dans mes propres tests visuels mobiles.</p>

<p><strong>Étape 1 — Spécification</strong></p>
<ul>
<li>Définir la population cible et les sous-groupes d’intérêt (âge, device, accessibilité).</li>
<li>Choisir les domaines cognitifs, la longueur du test, le format visuel et les contraintes WCAG.</li>
<li>Planifier les analyses (CTT/IRT, DIF, equating), enregistrer le protocole.</li>
</ul>

<p><strong>Étape 2 — Échantillonnage et recrutement</strong></p>
<ul>
<li>Stratifier l’échantillon, fixer les quotas, prévoir N test–retest.</li>
<li>Déployer des canaux variés pour éviter le biais de convenance (plateformes, partenariats éducatifs, diffusion locale).</li>
</ul>

<p><strong>Étape 3 — Collecte</strong></p>
<ul>
<li>Application responsive, consignes iconographiques, entraînement avec feedback.</li>
<li>Enregistrement exhaustif des métadonnées techniques, anonymisation.</li>
<li>Catch trials, randomisation contrôlée, durée 8–15 minutes.</li>
</ul>

<p><strong>Étape 4 — Nettoyage</strong></p>
<ul>
<li>Détection de doublons, filtres de qualité, gestion des temps extrêmes.</li>
<li>Exclusion des abandons, marquage des cas discutables pour analyses de sensibilité.</li>
</ul>

<p><strong>Étape 5 — Calibration</strong></p>
<ul>
<li>CTT initiale: difficultés, discriminations, alpha/oméga.</li>
<li>IRT: 2PL ou GPCM, estimation MML, vérification par bootstrap.</li>
<li>DIF par sexe, langue, device; révision des items biaisés.</li>
<li>Définition de la banque d’items finale et, le cas échéant, de l’algorithme adaptatif.</li>
</ul>

<p><strong>Étape 6 — Normalisation</strong></p>
<ul>
<li>Normes par âge (tranches) ou normes continues (splines/quantiles).</li>
<li>Transformation à l’échelle 100/15: IQ = 100 + 15 × z ou IQ = 100 + 15 × θ.</li>
<li>Lissage et garantie de monotonicité; contrôle des plafonds/planchers.</li>
</ul>

<p><strong>Étape 7 — Validation</strong></p>
<ul>
<li>Fidélité test–retest, SEM par niveau, validité convergente (ex. corrélations avec matrices standards) et divergente (faible corrélation temps de réaction pur).</li>
<li>Études d’utilité: durée perçue, fatigue, compréhension des consignes (tests utilisateurs).</li>
</ul>

<p><strong>Étape 8 — Publication et maintenance</strong></p>
<ul>
<li>Documentation publique des normes, rapport d’équité, scripts de conversion.</li>
<li>Plan de surveillance, calendrier de mise à jour, versionnage des normes.</li>
</ul>

<p><strong>Inputs indispensables</strong>: instrument final et ses métadonnées, échantillon stratifié, logs complets, décisions d’exclusion préenregistrées.</p>

<p><strong>Outputs</strong>: banque d’items calibrée, tables de conversion bruts→IQ, algorithme d’estimation, rapports de fidélité/validité/équité, spécification d’accessibilité.</p>

<p><strong>Principaux risques</strong> et parades:</p>
<ul>
<li><strong>Échantillon de convenance</strong> trop homogène: diversifier les sources, pondérer si nécessaire mais avec parcimonie (on préfère collecter davantage).</li>
<li><strong>Instabilité aux extrêmes</strong>: allonger légèrement la queue difficile, calibrer avec priors, rapporter des intervalles plutôt que des points.</li>
<li><strong>Effet device</strong> non corrigé: design responsive, tests A/B par gabarit d’écran, possible équating par device si les écarts persistent.</li>
<li><strong>Surajustement IRT</strong>: garder des paramètres simples, vérifier l’invariance et la qualité d’ajustement item par item.</li>
<li><strong>Non-conformité WCAG</strong>: audit externe, tests avec participants daltoniens, checklists systématiques.</li>
</ul>

<h2>Transparence sur les limites: ce que mesure vraiment votre score</h2>
<p>Un test visuel mobile de 10 minutes ne résume pas «votre intelligence». Il capture une estimation d’un facteur de <strong>raisonnement visuo-spatial</strong> dans un contexte spécifique, avec une incertitude chiffrable. Les corrélations avec des mesures plus longues sont élevées mais pas parfaites. Les contextes d’usage doivent être explicités: <strong>auto-évaluation, recherche, pré-screening</strong>. On ne l’utilise pas pour des décisions à fort enjeu sans corroboration.</p>

<p>Je recommande d’afficher, dans l’interface de résultats, trois messages simples:</p>
<ul>
<li><strong>Ce que le test mesure</strong> (raisonnement visuel), et ce qu’il ne mesure pas (mémoire verbale, connaissances culturelles).</li>
<li><strong>La précision</strong> (SEM et intervalle) et la durée de validité des normes (version + année).</li>
<li><strong>Les facteurs externes</strong> susceptibles d’influencer le score: fatigue, distraction, taille d’écran, luminosité.</li>
</ul>

<p>Éthique anti clickbait oblige: pas de promesses de «profil de génie». On fournit des infos actionnables: comment améliorer les conditions de passation, comment interpréter un écart entre sous-tests, et pourquoi repasser le test n’est pas un outil de «gamification» mais une mesure qui a besoin d’un intervalle (au moins 3 à 6 mois) pour éviter les effets d’apprentissage.</p>

<h2>Vers des normes vivantes et auditées</h2>
<p>La norme n’est pas un sceau éternel; c’est une photographie méthodiquement prise, puis régulièrement actualisée. Je plaide pour des <strong>normes vivantes</strong> mais stables: stables pour que vos scores d’aujourd’hui restent comparables demain; vivantes pour intégrer les progrès d’UX, d’accessibilité et de psychométrie. Cela suppose un écosystème ouvert: protocoles publics, audits externes, et, lorsqu’on s’y prête, des jeux de données de calibration déposés sur des dépôts de recherche.</p>

<p>La prochaine frontière? Lier finement <strong>accessibilité et information psychométrique</strong>: concevoir des items qui gardent leur pouvoir de discrimination tout en se rendant universellement lisibles, et publier la courbe SEM en fonction des réglages d’accessibilité choisis par l’utilisateur. Quand l’UX moderne rencontre la mesure fiable, la norme cesse d’être une boîte noire et devient un contrat: clair, équitable et utile.</p>