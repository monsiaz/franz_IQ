<p>
Je conçois des tests de QI visuels, mobiles, et sans jargon, et je suis souvent confronté à une question brûlante: pourquoi les scores de QI ont-ils augmenté au fil des décennies? Ce phénomène, appelé « effet Flynn » (du nom de James R. Flynn qui l’a documenté dans les années 1980), est fascinant autant qu’il est mal compris. Il ne dit pas que nos cerveaux ont muté d’une génération à l’autre; il dit plutôt que nos performances relatives, à des tâches standardisées, ont changé avec notre environnement. Dans ce texte, je démystifie l’effet Flynn avec mes lunettes de psychométricien: clarté visuelle, rigueur de mesure, accessibilité, transparence des limites, et éthique sans promesses trompeuses.
</p>

<h2>Ce que mesure vraiment l’effet Flynn: une affaire de normes et de contextes, pas de super-pouvoirs</h2>
<p>
Un QI est un score <strong>normé</strong>. Cela signifie qu’on compare une personne à un groupe de référence (même tranche d’âge), et que la moyenne de ce groupe est fixée à 100 avec un écart-type de 15. Or, les éditeurs renormalisent régulièrement leurs tests (tous les 10 à 15 ans) pour maintenir cette moyenne à 100. Entre deux versions, on observe souvent que <strong>le même score brut</strong> (le nombre de bonnes réponses) correspond à un QI plus élevé sur l’ancienne norme que sur la nouvelle: c’est l’effet Flynn « en action ».
</p>

<p>
Imaginez une matrice 3×3 à compléter (type Raven). En 1990, 22 bonnes réponses sur 36 pouvaient valoir QI 105. En 2020, si la population s’est améliorée sur ce type de raisonnement visuel, 22/36 peut ne plus valoir que QI 100. <strong>Le cerveau ne s’est pas rapetissé; la référence s’est déplacée</strong>. L’effet Flynn décrit ce déplacement moyen dans le temps.
</p>

<p>
Flynn a noté des hausses particulièrement marquées sur les tâches visuelles et abstraites au XXe siècle, avec des gains de l’ordre de 2 à 3 points de QI par décennie dans de nombreux pays industrialisés. Des batteries récentes confirment que ces gains n’étaient pas uniformes: la compréhension verbale ou le vocabulaire augmentaient moins que les matrices ou certaines tâches de classification. Une méta-analyse (Pietschnig et Voracek, 2015) a synthétisé des données internationales et confirmé des hausses robustes, tout en montrant que le rythme varie selon les périodes et les sous-tests.
</p>

<h3>Repères chronologiques utiles</h3>
<p>
• 1930–1970: gains rapides dans plusieurs pays sur les tâches non verbales (industrialisation, scolarisation de masse, nutrition en hausse).
</p>

<p>
• 1980–2000: consolidation et ralentissements selon les régions; documentation systématique par Flynn (1984, 1987).
</p>

<p>
• 2000–2015: signaux de plateaux et parfois de régressions dans les pays nordiques (Teasdale et Owen au Danemark; Bratsberg et Rogeberg en Norvège).
</p>

<p>
• 2015–2025: paysage contrasté, avec des données indiquant des tendances stables ou hétérogènes selon les cohortes, les sous-tests et les pays; montée des mesures numériques et des enjeux d’invariance.
</p>

<h2>D’où viennent les gains? Des causes multiples, plausibles et cumulatives</h2>
<p>
Il n’y a pas de baguette magique. L’effet Flynn est <strong>multi-factoriel</strong> et <strong>contexte-dépendant</strong>. Les hypothèses les mieux étayées empilent des effets de taille moyenne plutôt que de chercher une cause unique.
</p>

<p>
• <strong>Nutrition et santé de l’enfance</strong>: Amélioration de la nutrition, vaccination, baisse des infections chroniques, iodation du sel, et surtout baisse de l’exposition au plomb (réduction de l’essence plombée) ont des effets cognitifs mesurables. La littérature en santé publique montre des liens puissants entre plomb et fonctions exécutives. Mieux nourris, mieux protégés, les enfants réussissent mieux aux tâches de raisonnement.
</p>

<p>
• <strong>Scolarisation plus longue et pédagogie plus abstraite</strong>: Allongement de la scolarité, pré-scolarisation plus fréquente, et un glissement des pédagogies vers l’abstraction, les graphiques, les schémas, le « pourquoi » plutôt que le « quoi ». Flynn l’a souligné: nous sommes devenus plus familiers du raisonnement décontextualisé que les matrices demandent.
</p>

<p>
• <strong>Complexité cognitive du quotidien</strong>: Greenfield et d’autres ont argumenté que le travail, les interfaces numériques, les jeux vidéo et les médias multiplient les situations où il faut <em>déduire des règles visuelles</em>, manipuler des symboles, basculer d’un cadre à un autre. Les « environnements riches en signaux » entraînent exactement ce que mes tests mesurent: sélection de règles, inhibition, catégorisation rapide.
</p>

<p>
• <strong>Familles plus petites et attention parentale</strong>: Avec moins d’enfants, il y a en moyenne davantage de langage dirigé vers l’enfant, plus de livres, plus d’interactions individualisées. La taille de la fratrie fait partie des corrélats environnementaux répétés dans les études.
</p>

<p>
• <strong>Exposition aux formats de test</strong>: Sans réduire l’effet Flynn à « on triche mieux », il est raisonnable d’inclure une familiarité croissante avec les formats de questions, les consignes, la navigation sur écran, voire l’idée même de « chercher la règle la plus simple qui complète un motif ». Cela joue, mais les hausses observées sur des tâches inédites suggèrent que ce n’est qu’un morceau du puzzle.
</p>

<p>
• <strong>Effets sociétaux globaux</strong>: Urbanisation, professions plus cognitives, plus de femmes et de minorités dans l’enseignement supérieur, diffusion de la culture scientifique, accès massif à l’information. Ritchie et Tucker-Drob ont synthétisé l’ampleur des contributions éducatives, montrant que l’instruction produit des gains de QI substantiels, indépendants des différences initiales.
</p>

<p>
<strong>Important</strong>: l’effet Flynn n’est pas opposé aux différences individuelles stables. On peut reconnaître des influences génétiques sur les différences interindividuelles tout en notant que <strong>le niveau moyen</strong> change avec l’environnement. Les analyses « within-family » en Norvège (Bratsberg et Rogeberg, 2018) ont précisément montré que les variations cohortes se retrouvent entre frères d’âges différents, ce qui pointe vers des facteurs environnementaux plutôt que vers une sélection génétique rapide.
</p>

<h2>Ce qui augmente vraiment: profils de gains dans les tâches visuelles modernes</h2>
<p>
Je conçois des tâches où l’on doit inférer une règle visuelle en quelques secondes. Quand on observe l’effet Flynn, ce sont <strong>ces familles d’items</strong> qui « portent » souvent les gains. Quelques exemples concrets pour ancrer:
</p>

<p>
• <strong>Matrices de règles combinées</strong>: Une grille 3×3 où la forme se déplace en ligne, la couleur suit un cycle, et le nombre de segments augmente en colonne. Les gains se manifestent sur la capacité à <em>séparer les dimensions</em> (position/couleur/nombre), tester rapidement des hypothèses et inhiber les régularités trompeuses. Les jeunes générations, plus exposées aux interfaces multi-couches, semblent plus à l’aise avec la « décomposition factorielle » d’un motif.
</p>

<p>
• <strong>Séries figurales</strong>: On présente un carré rempli de triangles, puis un carré avec un triangle en moins, puis un autre avec une rotation de 90°, et l’on demande la suite logique. L’effet Flynn apparaît dans la rapidité à distinguer « transformation géométrique » vs « règle arithmétique de décompte » et à choisir la bonne règle sur un écran tactile, sans texte explicatif.
</p>

<p>
• <strong>Catégorisation abstraite</strong>: Sur mobile, je propose parfois des ensembles de pictogrammes où la règle est du type « même parité de points et même orientation », alors que la couleur est un distracteur. Les cohortes récentes sélectionnent plus souvent la dimension pertinente du premier coup, avec moins d’erreurs persévératives.
</p>

<p>
• <strong>Intégration visuo-spatiale</strong>: Quatre tuiles grisées et une tuile qui change de motif à chaque pas; l’utilisateur doit simuler mentalement l’addition XOR des motifs. Les gains se voient sur la charge de travail visuo-spatiale à court terme et l’application d’une règle booléenne simple.
</p>

<p>
En revanche, les gains sur le <strong>vocabulaire</strong> ou la <strong>connaissance factuelle</strong> sont plus hétérogènes. Les tâches de compréhension verbale profitent de la scolarité et des médias, mais l’abondance d’information ne se traduit pas mécaniquement en meilleures performances à des épreuves standardisées qui exigent précision sémantique et structure. Dans les batteries traditionnelles (Wechsler, par exemple), les sous-tests « Similarités » peuvent augmenter plus que « Vocabulaire », signe d’un bénéfice plus fort sur le <em>raisonnement conceptuel</em> que sur la simple accumulation lexicale.
</p>

<p>
Du point de vue psychométrique, il existe un débat sur la « direction » des gains: certains travaux montrent que les hausses ne s’alignent pas parfaitement avec le facteur g (la variance commune à de nombreuses tâches), d’autres observent de fortes hausses sur Raven (longtemps considéré comme très g). La réalité est nuancée: <strong>les gains suivent des dimensions de compétence entraînées par l’environnement</strong> (abstraction, traitement de règles, flexibilité), ce qui recouvre en partie g sans s’y superposer exactement.
</p>

<p>
Indépendamment, un point souvent oublié: <strong>l’accessibilité visuelle</strong>. Quand on garantit des contrastes suffisants (au moins 4,5:1 pour les éléments critiques, 3:1 pour les gros motifs), une hiérarchie visuelle nette (espacements cohérents, cibles tactiles de 9 mm minimum), et des alternatives non colorimétriques (formes + textures), on mesure mieux le raisonnement que la capacité à deviner des symboles peu contrastés. Une partie des « gains » historiques peut être masquée ou amplifiée par la qualité des supports et des rendus. C’est pourquoi, dans mes tests, je pratique des <strong>audits WCAG</strong> et des simulations de daltonisme pour éviter les faux écarts de performance.
</p>

<h2>Revers, plateaux et illusions de mesure: ce que disent les données récentes</h2>
<p>
Depuis les années 2000, plusieurs pays ont observé un ralentissement, voire un recul des scores standardisés. Au Danemark, Teasdale et Owen ont décrit un plateau puis un déclin chez les conscrits; en Norvège, Bratsberg et Rogeberg ont noté des baisses intra-familiales selon les cohortes. La cause n’est pas une simple explication unique (ni immigration, ni « déclin génétique » rapide). Les hypothèses incluent une évolution des pédagogies, des inégalités plus marquées, une variation de la motivation aux tests, des expositions environnementales nouvelles, ou des changements dans l’échantillonnage.
</p>

<p>
Je vois trois <strong>mises en garde méthodologiques</strong> essentielles quand on lit ces résultats:
</p>

<p>
• <strong>Invariance de mesure</strong>: Un test renormé n’est pas nécessairement identique. Si la batterie introduit plus d’items de type X et moins d’items de type Y, on peut déplacer la difficulté moyenne indépendamment des compétences sous-jacentes. En IRT, la non-invariance des paramètres d’items (drift) peut mimer un déclin ou une hausse. Il faut contrôler des <em>items ancrés</em> stables dans le temps et tester formellement l’invariance factorielle.
</p>

<p>
• <strong>Mode de passation</strong>: Le passage du papier-crayon au mobile change la latence, l’ergonomie et la perception. Un cercle gris peu contrasté sur un écran LCD bas de gamme devient une difficulté non souhaitée. Sans calibrage multi-appareils (densité de pixels, luminance), on risque de mesurer l’écran plus que la personne. C’est aussi de l’effet Flynn… mais de l’effet écran.
</p>

<p>
• <strong>Motivation et contexte</strong>: Les conscrits, les élèves et les volontaires de plateformes en ligne n’abordent pas un test avec la même implication. Les études qui contrôlent l’incitation (bonus, feedback, instructions qui valorisent l’effort) montrent des écarts non négligeables. Interpréter un déclin brut sans métadonnées sur la motivation est périlleux.
</p>

<p>
Côté « petites mythologies », rétablissons quelques faits nets.
</p>

<h3>Idées reçues vs faits</h3>
<p>
• <strong>Idée reçue:</strong> « L’effet Flynn prouve que les humains sont plus intelligents. » <strong>Fait:</strong> Il prouve que les performances relatives à des tâches standardisées se sont améliorées dans des environnements spécifiques. L’intelligence est multidimensionnelle; un QI est une estimation normée, pas un thermomètre absolu.
</p>

<p>
• <strong>Idée reçue:</strong> « L’effet Flynn est mort. » <strong>Fait:</strong> On observe des ralentissements et des baisses locales, mais aussi des stabilités et des hausses ailleurs. Le phénomène est <em>historique et géographique</em>, pas un destin universel.
</p>

<p>
• <strong>Idée reçue:</strong> « C’est juste de l’entraînement aux tests. » <strong>Fait:</strong> L’entraînement existe, mais les gains sont visibles sur des tâches inédites et dans des sous-tests peu sensibles à la pratique explicite. Les facteurs de santé, d’éducation et de complexité environnementale sont déterminants.
</p>

<p>
• <strong>Idée reçue:</strong> « C’est une illusion statistique. » <strong>Fait:</strong> Les artefacts existent (mauvais ancrages, changements d’items), mais de multiples séries indépendantes et des analyses intra-familiales confirment un composant environnemental réel.
</p>

<p>
Enfin, un mot d’éthique: <strong>éviter le sensationnalisme</strong>. Dire « notre QI s’effondre » ou « nos enfants sont des génies » n’aide personne. Ce qui aide, c’est de comprendre <em>quelles compétences</em> progressent ou régressent, dans <em>quels contextes</em>, et comment <em>mesurer proprement</em>.
</p>

<h2>Mesurer proprement aujourd’hui: IRT, ancrages visuels, renormage continu et accessibilité</h2>
<p>
Quand je publie un test, je me donne trois exigences: <strong>clarté visuelle universelle</strong>, <strong>rigueur psychométrique</strong>, <strong>accessibilité par design</strong>. L’effet Flynn oblige à faire mieux sur ces trois axes.
</p>

<p>
• <strong>Clarté visuelle universelle</strong>: Mes items sont pensés pour minimiser les biais culturels et linguistiques. Pas de texte dans la tâche, seulement des consignes illustrées. Les règles visuelles (alternance, symétrie, progression) sont explicites par redondance des indices: formes + textures + position. Les couleurs n’encoderont jamais l’unique clé. Les contrastes suivent WCAG 2.1 AA: 4,5:1 pour les éléments fins, 3:1 pour les étendus. J’intègre des marges respirantes (8–12 px d’écart visuel ratio à la taille des éléments) et des cibles tactiles d’au moins 44 px.
</p>

<p>
• <strong>Rigueur psychométrique</strong>: Je calibre chaque item en IRT (modèle à 2 ou 3 paramètres selon le type) sur des échantillons stratifiés par âge, appareil et contexte. J’effectue des <em>analyses DIF</em> (fonctionnement différentiel des items) par sexe, langue, daltonisme simulé, et type d’écran. J’utilise des items ancrés pour relier les versions dans le temps, testant l’invariance métrique et scalaire. Quand l’invariance échoue, je retire ou je réécris l’item: pas de cache-misère.
</p>

<p>
• <strong>Renormage continu et transparence</strong>: Plutôt que d’attendre 10 ans, je pratique un renormage continu par fenêtres temporelles glissantes, avec surveillance des biais d’échantillonnage. Le score présenté à un utilisateur est une <strong>estimation</strong> avec intervalle de confiance, et je documente la date de référence des normes. Un même score brut peut changer d’interprétation si la population bouge: je l’explique, noir sur blanc.
</p>

<p>
• <strong>Accessibilité et alternatives</strong>: Sur mobile, je propose un mode « contraste renforcé » et un mode « animations réduites ». Les items temporisés sont livrés avec une marge de latence compensée par l’appareil détecté. Si une tâche repose sur la couleur, une alternative par texture est automatiquement activée. L’accessibilité n’est pas un « plus »: c’est le minimum pour mesurer ce qu’on prétend mesurer.
</p>

<p>
Exemple de pipeline concret:
</p>

<p>
1) Conception d’un lot de 60 items de matrices avec trois familles de règles (position, transformation, comptage).
</p>

<p>
2) Pré-test sur 1 500 personnes, échantillon stratifié par tranche d’âge, type d’appareil (iOS/Android, petit/grand écran), langue, et handicap visuel déclaré.
</p>

<p>
3) Calibration IRT, élimination des items aux paramètres instables, test DIF par groupes et par luminance d’écran mesurée.
</p>

<p>
4) Création d’un test adaptatif (CAT) avec 25 items, ancrage de 6 items invariants pour le suivi longitudinal.
</p>

<p>
5) Déploiement et renormage glissant mensuel, rapportant l’évolution des seuils d’items ancrés (détection d’un « mini-effet Flynn » local).
</p>

<p>
6) Rapports transparents: précision par sous-test, dates de normes, avertissement sur l’interprétation individuelle, options d’accessibilité activées.
</p>

<p>
Ainsi, si une cohorte nouvellement scolarisée améliore sensiblement la <em>séparation des dimensions</em> en matrices, je le verrai d’abord dans les paramètres d’items (discrimination accrue sur la dimension « règles combinées »), puis, éventuellement, dans les normes. Je n’attribue pas cette progression à un mystère: je la relie à des changements observables dans l’éducation ou la culture visuelle (par exemple, généralisation des interfaces multi-panneaux et de la manipulation de couches).
</p>

<p>
Dernière vigilance: <strong>les délais</strong>. On ne déclare pas une tendance sur six mois. Les cycles scolaires, les effets de nouveauté, ou une campagne médiatique peuvent gonfler temporairement des scores. Dans mes publications, je fournis au minimum 24 mois de suivi avant de parler de « signal ».
</p>

<h2>Vers des normes dynamiques et des tests plus justes</h2>
<p>
L’effet Flynn nous rappelle que le QI est un instrument sensible au monde qui l’entoure. Plutôt que de s’alarmer ou de fanfaronner, j’y vois une invitation à <strong>mieux concevoir</strong> et à <strong>mieux informer</strong>. Mieux concevoir, c’est faire des items visuels clairs, culture-fair, accessibles par principe, et psychométriquement ancrés. Mieux informer, c’est dire à chaque personne: « voici une estimation, datée, avec sa marge d’erreur; voici ce qu’elle signifie dans votre cohorte; voici ce qu’elle ne dit pas. »
</p>

<p>
À court terme, je m’attends à davantage de <strong>normes dynamiques</strong>, dérivées en continu de larges échantillons et reliées par des items invariants. Les tests sur mobile, bien calibrés, permettent cette granularité. Les mêmes outils que j’utilise pour détecter un item mal contrasté me servent déjà à détecter un <em>glissement de compétence</em> dans une tranche d’âge.
</p>

<p>
À moyen terme, je voudrais voir se généraliser des <strong>profils de compétence</strong> plus explicites, qui disent: « vous excellez à isoler une règle visuelle sous contrainte de temps; vous êtes dans la moyenne pour la recombinaison spatiale; vous avez un point faible dans l’inhibition de distracteurs chromatiques ». Cela a plus de valeur pratique que de fétichiser un point de QI.
</p>

<p>
À long terme, si l’on respecte la rigueur (invariance, ancrages, IRT), la clarté visuelle (WCAG comme plancher), et l’éthique (pas de clickbait, pas de surpromesse), alors les tests de QI auront leur utilité: non pas comme totems, mais comme <strong>baromètres</strong> d’écarts pertinents, au service d’apprentissages plus justes. L’effet Flynn, qu’il monte ou qu’il se tasse, continuera d’être une fenêtre sur la manière dont nos environnements forment – ou freinent – nos façons de raisonner. Et nous avons notre part à jouer: concevoir des mesures qui respectent les personnes, et qui éclairent sans aveugler.
</p>